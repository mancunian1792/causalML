{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import Importance, EmpiricalMarginal\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving the alias and cpt tables for the model\n",
    "X_alias = [\"promotion0\", \"promotion1\"]\n",
    "Y_alias = [\"not-renewed\", \"renewed\"]\n",
    "Z_alias = [\"unhappy\", \"happy\"]\n",
    "\n",
    "\n",
    "Z_prob = torch.tensor([0.5092,0.4908])\n",
    "X_prob = torch.tensor([[0.247, 0.753], [0.763, 0.237]])\n",
    "Y_prob = torch.tensor([[[0.068, 0.932], [0.267, 0.733]],\n",
    "                     [[0.131, 0.869], [0.313, 0.687]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.a \n",
    "Build the model with Pyro using the values in the table.  Use `pyro.condition` to calculate the causal effect by adjusting for happiness. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    Z = pyro.sample(\"Z\", dist.Categorical(probs=Z_prob))\n",
    "    X = pyro.sample(\"X\", dist.Categorical(probs=X_prob[Z]))\n",
    "    Y = pyro.sample(\"Y\", dist.Categorical(probs=Y_prob[X][Z]))\n",
    "    return{'X': X, 'Y': Y, 'Z': Z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are interested in the average causal effect $P(Y=1|\\text{do}(X=0)) - P(Y=1|\\text{do}(X=1))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustmentFormula(x_cond, z_probs):\n",
    "    Z_conditons=[{'Z':torch.tensor(0)}, {'Z': torch.tensor(1)}]\n",
    "    effect = 0.0\n",
    "    for idx in range(len(z_probs)):\n",
    "        data = {}\n",
    "        data.update(x_cond)\n",
    "        data.update(Z_conditons[idx])\n",
    "        \n",
    "        conditioned_model = pyro.condition(model, data= data)\n",
    "        T_samples = [conditioned_model()['Y'] for _ in range(1000)]\n",
    "        T_unique, T_counts = np.unique(T_samples, return_counts=True)\n",
    "        Y_prob = T_counts[1]/ 1000\n",
    "        effect += (Y_prob * z_probs[idx])\n",
    "    return effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_Y1_X0 = adjustmentFormula({\"X\": torch.tensor(0)}, [0.5092, 0.4908])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_Y1_X1 = adjustmentFormula({\"X\": torch.tensor(1)}, [0.5092, 0.4908])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05323920000000004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect_Y1_X0 - effect_Y1_X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.b\n",
    "Use `pyro.do` to calculate the causal effect by adjusting for happiness. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interventionUsingDo(x_cond):\n",
    "    intervention_model = pyro.do(model, data = x_cond)\n",
    "    Y_posterior_intervened = pyro.infer.Importance(intervention_model, num_samples=10000).run()\n",
    "    Y_marginal_intervened = EmpiricalMarginal(Y_posterior_intervened,\"Y\")\n",
    "    Y_samples_intervened = [Y_marginal_intervened().item() for _ in range(10000)]\n",
    "    Y_unique_intervened, Y_counts_intervened = np.unique(Y_samples_intervened, return_counts=True)\n",
    "    return Y_counts_intervened[1]/ len(Y_samples_intervened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_Y1_X0_do = interventionUsingDo({'X': torch.tensor(0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_Y1_X1_do = interventionUsingDo({'X': torch.tensor(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059599999999999986"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect_Y1_X0_do - effect_Y1_X1_do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both the causal effect obtained in 2.1.a and 2.a.b are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "You are a data scientist investigating the effects of social media use on purchasing a product. You assume the dag shown below. User info here is unobserved. One of the team members argues that social media usage does not drive purchase based on Table 1. Only 15% social media user made the purchase, while 90.25% non social media users made the purchase. Moreover, within each group, no-adblock and adblock, social media users show a much lower rate of purchase than non social media users. However, another team member argues that social media usage increases purchases. When we look at each group, social media user and non social media user as show in Table 2 (Table 1 and Table 2 both represent the same dataset),  advertisement increases purchases in both groups. Among social media users, purchases increases from 10% to 15% for people who have seen advertisement. Among non social media users, purchases increases from 90% to 95% for people who have seen advertisement. Which view is right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving the alias and cpt tables for the model\n",
    "X_alias = [\"no-social\", \"social\"]\n",
    "Y_alias = [\"no-ad\", \"ad\"]\n",
    "Z_alias = [\"no-purchase\", \"purchase\"]\n",
    "\n",
    "\n",
    "X2_prob = torch.tensor([0.5, 0.5])\n",
    "Z2_prob = torch.tensor([[0.95, 0.05], [0.05, 0.95]])\n",
    "Y2_prob = torch.tensor([[0.14, 0.86], [0.81, 0.19]])\n",
    "\n",
    "\n",
    "def socialMediaModel():\n",
    "    X_2 = pyro.sample(\"X2\", dist.Categorical(probs=X2_prob))\n",
    "    Z_2 = pyro.sample(\"Z2\", dist.Categorical(probs=Z2_prob[X_2]))\n",
    "    Y_2 = pyro.sample(\"Y2\", dist.Categorical(probs=Y2_prob[Z_2]))\n",
    "    return{'X2': X_2, 'Y2': Y_2, 'Z2': Z_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.a\n",
    "User info is unobserved.  Use `pyro.condition` to calculate the causal effect of social media on product purchase using front-door adjustment (Section 3.4 in [Front Door Criterion](http://bayes.cs.ucla.edu/PRIMER/primer-ch3.pdf)).(5 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frontDoorAdjustment(x_conds, x_prob, x_idx):\n",
    "    Z_conditions = [{\"Z2\": torch.tensor(0)}, {\"Z2\": torch.tensor(1)}]\n",
    "    cumProb = 0.0\n",
    "    for idx in range(len(Z_conditions)):\n",
    "        first_condition = {}\n",
    "        first_condition.update(x_conds[x_idx])\n",
    "        z_condition_model = pyro.condition(fn=socialMediaModel, data = first_condition)\n",
    "        Z_samples = [z_condition_model()['Z2'] for _ in range(1000)]\n",
    "        Z_unique, Z_counts = np.unique(Z_samples, return_counts=True)\n",
    "        Z_prob = Z_counts[idx]/ 1000\n",
    "        \n",
    "        # Finding the sum part for each z - iteration\n",
    "        innerProb = 0.0\n",
    "        for idx1 in range(len(x_conds)):\n",
    "            second_condition = {}\n",
    "            second_condition.update(Z_conditions[idx])\n",
    "            second_condition.update(x_conds[idx1])\n",
    "            y_condition_model = pyro.condition(socialMediaModel, data=second_condition)\n",
    "            Y_samples = [y_condition_model()['Y2'] for _ in range(1000)]\n",
    "            Y_unique, Y_counts = np.unique(Y_samples, return_counts=True)\n",
    "            Y_prob = Y_counts[1]/ 1000\n",
    "            innerProb += (Y_prob * x_prob[idx1])\n",
    "        cumProb += (Z_prob * innerProb)\n",
    "    return cumProb\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_conds = [{\"X2\": torch.tensor(0)}, {\"X2\": torch.tensor(1)}]\n",
    "X_prob_1 = [0.5, 0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6186054999999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontDoorAdjustment(X_conds, X_prob_1, 0) -  frontDoorAdjustment(X_conds, X_prob_1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.b\n",
    "Verify your result using do-calculus with `pyro.do`.($P(Y=1|\\text{do}(X=0)) - P(Y=1|\\text{do}(X=1))$) (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interventionUsingDoSocial(x_cond):\n",
    "    intervention_model = pyro.do(socialMediaModel, data = x_cond)\n",
    "    Y_posterior_intervened = pyro.infer.Importance(intervention_model, num_samples=10000).run()\n",
    "    Y_marginal_intervened = EmpiricalMarginal(Y_posterior_intervened,\"Y2\")\n",
    "    Y_samples_intervened = [Y_marginal_intervened().item() for _ in range(10000)]\n",
    "    Y_unique_intervened, Y_counts_intervened = np.unique(Y_samples_intervened, return_counts=True)\n",
    "    return Y_counts_intervened[1]/ len(Y_samples_intervened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6065999999999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interventionUsingDoSocial({\"X2\": torch.tensor(0)}) - interventionUsingDoSocial({\"X2\": torch.tensor(1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both the causal effect obtained in 2.2.a and 2.2.b are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Defining the propensity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity(x, z):\n",
    "    return X_prob[z][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7630)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensity(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Displaying the 10 samples generated for the model given in 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "zs = []\n",
    "ps = []\n",
    "trace_handler = pyro.poutine.trace(model)\n",
    "for i in range(1000):\n",
    "    trace = trace_handler.get_trace()\n",
    "    x = trace.nodes['X']['value']\n",
    "    y = trace.nodes['Y']['value']\n",
    "    z = trace.nodes['Z']['value']\n",
    "    log_prob = trace.log_prob_sum()\n",
    "    p = np.exp(log_prob)\n",
    "    xs.append(int(x))\n",
    "    ys.append(int(y))\n",
    "    zs.append(int(z))\n",
    "    ps.append(p)\n",
    "data = pd.DataFrame({\"X\": xs, \"Y\": ys, \"Z\": zs, \"P\": ps})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.3332)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.3332)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.2745)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.0502)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.3332)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.1000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.3332)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.2745)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.0799)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.2745)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y  Z               P\n",
       "0  1  1  0  tensor(0.3332)\n",
       "1  1  1  0  tensor(0.3332)\n",
       "2  0  1  1  tensor(0.2745)\n",
       "3  1  0  0  tensor(0.0502)\n",
       "4  1  1  0  tensor(0.3332)\n",
       "5  0  0  1  tensor(0.1000)\n",
       "6  1  1  0  tensor(0.3332)\n",
       "7  0  1  1  tensor(0.2745)\n",
       "8  1  1  1  tensor(0.0799)\n",
       "9  0  1  1  tensor(0.2745)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Computing the inverse probability weighting using propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the data generated above, i re-weight the joint probability by propensity.\n",
    "\n",
    "data[\"inverse_weighted_prob\"] = data.apply(lambda x: x[\"P\"]/ (propensity(x[\"X\"], x[\"Z\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>P</th>\n",
       "      <th>inverse_weighted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.3332)</td>\n",
       "      <td>tensor(0.4425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.2745)</td>\n",
       "      <td>tensor(0.3598)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.0502)</td>\n",
       "      <td>tensor(0.0667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.1000)</td>\n",
       "      <td>tensor(0.1310)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.0799)</td>\n",
       "      <td>tensor(0.3372)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.1172)</td>\n",
       "      <td>tensor(0.4746)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.0364)</td>\n",
       "      <td>tensor(0.1536)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.0086)</td>\n",
       "      <td>tensor(0.0346)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y  Z               P inverse_weighted_prob\n",
       "0  1  1  0  tensor(0.3332)        tensor(0.4425)\n",
       "1  0  1  1  tensor(0.2745)        tensor(0.3598)\n",
       "2  1  0  0  tensor(0.0502)        tensor(0.0667)\n",
       "3  0  0  1  tensor(0.1000)        tensor(0.1310)\n",
       "4  1  1  1  tensor(0.0799)        tensor(0.3372)\n",
       "5  0  1  0  tensor(0.1172)        tensor(0.4746)\n",
       "6  1  0  1  tensor(0.0364)        tensor(0.1536)\n",
       "7  0  0  0  tensor(0.0086)        tensor(0.0346)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset=['X', 'Y', 'Z'], inplace=True)\n",
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = data[['X', 'Y', 'Z']].apply(lambda x: x.to_dict(), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_weighted_prob = list(data[\"inverse_weighted_prob\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Generating samples from the inverse weighting probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_samples = pd.DataFrame.from_records(random.choices(combinations, inv_weighted_prob,k=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y  Z\n",
       "0  1  1  1\n",
       "1  0  1  0\n",
       "2  0  1  1\n",
       "3  0  1  0\n",
       "4  1  0  1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Checking whether the causal estimate is same as 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterIt(df, var, value):\n",
    "    return df[df[var]==value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeProb(df, var, value):\n",
    "    return sum(df[var]==value)/(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causalEffect(df, xval):\n",
    "    cumProb = 0.0\n",
    "    for z in range(df[\"Z\"].nunique()):\n",
    "        ydf = filterIt(filterIt(df, \"Z\", z), \"X\", xval)\n",
    "        yprob = computeProb(ydf, \"Y\", 1)\n",
    "        zprob = computeProb(df, \"Z\", z)\n",
    "        cumProb+= (yprob * zprob)\n",
    "    return cumProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06200804901366552"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causalEffect(weighted_samples, 0) - causalEffect(weighted_samples, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The causal estimate is similar to what is obtained in 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Defining the model and generating 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scm1():\n",
    "    X = pyro.sample('X', dist.Normal(0.0, 1.0))\n",
    "    Y = X ** 2 + pyro.sample('Ny', dist.Normal(0.0, 1.0))\n",
    "    Y = pyro.sample('Y', dist.Normal(Y, 0.001))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The value of x is -0.5521014332771301 and the value of y is 2.8549365997314453\n",
      " The value of x is -0.08818693459033966 and the value of y is 0.8312249183654785\n",
      " The value of x is 0.5461435317993164 and the value of y is 0.1130787804722786\n",
      " The value of x is -0.18929176032543182 and the value of y is -0.912778913974762\n",
      " The value of x is 0.41813671588897705 and the value of y is -1.5690648555755615\n",
      " The value of x is -0.2518658936023712 and the value of y is -1.1397367715835571\n",
      " The value of x is 0.09925052523612976 and the value of y is 0.8712673783302307\n",
      " The value of x is 1.3132648468017578 and the value of y is 0.6808860898017883\n",
      " The value of x is 1.1282209157943726 and the value of y is 0.7220373749732971\n",
      " The value of x is -1.107576847076416 and the value of y is 1.1398751735687256\n"
     ]
    }
   ],
   "source": [
    "trace_scm = pyro.poutine.trace(scm1)\n",
    "for _ in range(10):\n",
    "    trace = trace_scm.get_trace()\n",
    "    x = trace.nodes['X']['value']\n",
    "    y = trace.nodes['Y']['value']\n",
    "    print(f' The value of x is {x} and the value of y is {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.a The DAG can be represented as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://g.gravizo.com/svg?\n",
    " digraph G {\n",
    "   Nx -> X;\n",
    "   X -> Y;\n",
    "   Ny -> Y\n",
    " }\n",
    "'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The mean of the distribution $P_{Y}^{M}$is 0\n",
    "2. The variance of the distribution  $P_{Y}^{M}$ is 17 \n",
    "3. Y = 4 * N(0,1) + N(0,1) --> The variance gets squared when there's a multiplicative factor. --> 16 + 1 --> 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.c\n",
    "\n",
    "1. The mean of the distribution ${P_{Y}^{M:do(X=2)}}$ is 8 \n",
    "2. The variance of the distribution $P_{Y}^{M:do(X=2)}$ is 1\n",
    "3. Y = 4 * 2 (setting the value of x =2 ) + 0 --> Mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.d\n",
    "1. The distribution ${P_{Y}^{M:X=2}}$ doesn't differ from ${P_{Y}^{M:do(X=2)}}$ distribution because there isn't any other source that affects X. So, conditioning it or intervening on it doesn't make any difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.e is answered in the end , as the image is attached separately ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.f\n",
    "1. The mean of the distribution ${P_{X}^{M:do(Y=2)}}$ is 0\n",
    "2. The variance of the distribution  ${P_{X}^{M:do(Y=2)}}$ is 1\n",
    "3. Since the sources of Y are removed. The values of X doesn't affect Y in any way. Hence the mean and variance of X remains same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The value of x is 1.3833633661270142 and the value of y is 5.738138198852539\n",
      " The value of x is 0.07725183665752411 and the value of y is 0.3900867700576782\n",
      " The value of x is -0.7231635451316833 and the value of y is -3.6485979557037354\n",
      " The value of x is -1.0205142498016357 and the value of y is -3.050013542175293\n",
      " The value of x is 0.13883854448795319 and the value of y is 0.6668169498443604\n",
      " The value of x is 0.6039068698883057 and the value of y is 1.5654387474060059\n",
      " The value of x is 1.5974762439727783 and the value of y is 7.456148147583008\n",
      " The value of x is -0.814222514629364 and the value of y is -2.912876844406128\n",
      " The value of x is 0.9170505404472351 and the value of y is 2.855215549468994\n",
      " The value of x is 0.5865408778190613 and the value of y is 2.7083709239959717\n"
     ]
    }
   ],
   "source": [
    "def scm2():\n",
    "    X = pyro.sample('X', dist.Normal(0.0, 1.0))\n",
    "    Y = 4 * X + pyro.sample('Ny', dist.Normal(0.0, 1.0))\n",
    "    Y = pyro.sample('Y', dist.Normal(Y, 0.001))\n",
    "    return X, Y\n",
    "\n",
    "trace_scm = pyro.poutine.trace(scm2)\n",
    "for _ in range(10):\n",
    "    trace = trace_scm.get_trace()\n",
    "    x = trace.nodes['X']['value']\n",
    "    y = trace.nodes['Y']['value']\n",
    "    print(f' The value of x is {x} and the value of y is {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned_model = pyro.poutine.do(scm2, data={\"X\": torch.tensor(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = pyro.poutine.trace(conditioned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = []\n",
    "for _ in range(100):\n",
    "    trace = traced_model.get_trace()\n",
    "    y = trace.nodes['Y']['value']\n",
    "    y_vals.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  7.,  9., 15., 21., 19., 12.,  6.,  3.,  3.]),\n",
       " array([ 5.6756163,  6.182397 ,  6.6891775,  7.1959577,  7.7027383,\n",
       "         8.209518 ,  8.716299 ,  9.22308  ,  9.72986  , 10.236641 ,\n",
       "        10.743422 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0432205"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_vals) #approximately around 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mean is centered around 8, which is what we got for ${P_{Y}^{M:do(X=2)}}$ in 4.2.c and we stated in 4.2.d that the ${P_{Y}^{M:(X=2)}}$ distribution doesn't change much to ${P_{Y}^{M:do(X=2)}}$ distribution, which is what we see here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned_model_y = pyro.poutine.condition(scm2, data={\"Y\": torch.tensor(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 20/20 [00:05,  3.63it/s, step size=2.03e-04, acc. prob=0.942]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = pyro.infer.NUTS(conditioned_model_y)\n",
    "mcmc = pyro.infer.MCMC(nuts_kernel,\n",
    "            num_samples=10)\n",
    "mcmc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2253, 0.2256, 0.1948, 0.1952, 0.1953, 0.1953, 0.1951, 0.1947, 0.2294,\n",
       "        0.1509])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmc.get_samples()[\"X\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
