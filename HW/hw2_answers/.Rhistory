dataNew <- mlr::createDummyFeatures(data, cols = cat_vars)
#dataNew <- dataNew[,-c(3,7,11,16,25,26,32,37,39,50,51,58,61,65,69,75)]
# Removing the Multicollinearity variable - I have removed the code that does this. Don't worry about this. Used VIF function from car package to identify this. All the variables that had < 2 VIF value were removed.
#dataNew <- dataNew[,-c(4,6,7,10,13,25,26,35,36,42,43,47,48,52,55,59,60,61)]
?fastDummies::dummy_cols
# Changig the class of variable from numeric to factor
cat_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance", "BusinessTravel")
remove_one_dummy <-  c("Education.1", "EnvironmentSatisfaction.1", "JobInvolvement.1", "JobLevel.1", "JobSatisfaction.1", "PerformanceRating.3", "RelationshipSatisfaction.1", "StockOptionLevel.0", "WorkLifeBalance.1", "BusinessTravel.Non.Travel")
data$Education <- factor(data$Education)
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobInvolvement <- factor(data$JobInvolvement)
data$JobLevel <- factor(data$JobLevel)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$PerformanceRating <- factor(data$PerformanceRating)
data$RelationshipSatisfaction <- factor(data$RelationshipSatisfaction)
data$StockOptionLevel <- factor(data$StockOptionLevel)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
data$BusinessTravel <- factor(data$BusinessTravel)
dataNew1 <- dataNew[, -remove_one_dummy]
getIndex <- function(name) {}
# Changig the class of variable from numeric to factor
cat_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance", "BusinessTravel")
remove_one_dummy <-  c("Education.1", "EnvironmentSatisfaction.1", "JobInvolvement.1", "JobLevel.1", "JobSatisfaction.1", "PerformanceRating.3", "RelationshipSatisfaction.1", "StockOptionLevel.0", "WorkLifeBalance.1", "BusinessTravel.Non.Travel")
getIndex <- function(name) {
grep(name, colnames(df))
}
index <- lapply(remove_one_dummy, getIndex)
data$Education <- factor(data$Education)
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobInvolvement <- factor(data$JobInvolvement)
data$JobLevel <- factor(data$JobLevel)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$PerformanceRating <- factor(data$PerformanceRating)
data$RelationshipSatisfaction <- factor(data$RelationshipSatisfaction)
data$StockOptionLevel <- factor(data$StockOptionLevel)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
data$BusinessTravel <- factor(data$BusinessTravel)
index
getIndex <- function(name) {
grep(name, colnames(dataNew))
}
index <- unlist(lapply(remove_one_dummy, getIndex))
dataNew1 <- dataNew[, -index]
str(dataNew1)
library(car)
install.packages(car)
install.packages("car")
vif_output <- lm(Attrition ~., data = dataNew)
vif_res <- car::vif(vif_output)
dataNew <- mlr::createDummyFeatures(data, cols = cat_vars)
#Removing the dummy variable
dataNew <- dataNew[, -index]
#dataNew <- dataNew[,-c(3,7,11,16,25,26,32,37,39,50,51,58,61,65,69,75)]
# Removing the Multicollinearity variable - I have removed the code that does this. Don't worry about this. Used VIF function from car package to identify this. All the variables that had < 2 VIF value were removed.
#dataNew <- dataNew[,-c(4,6,7,10,13,25,26,35,36,42,43,47,48,52,55,59,60,61)]
vif_output <- lm(Attrition ~., data = dataNew)
vif_res <- car::vif(vif_output)
summary(vif_res)
print(vif_res)
vif_names <- names(vif_res)
while(any(vif_res > 2)){
var_with_max_vif <- names(which(vif_res == max(vif_res)))
vif_names <- vif_names[!(vif_names) %in% var_with_max_vif]
def_form <- as.formula(paste("Attrition ~" ,paste(vif_names, collapse = " +"),sep = ""))
vif_output <- lm(def_form, data = attira)
vif_res <- car::vif(vif_output)
}
vif_res
names(vif_res)
type(vif_res)
typeof(vif_res)
vif_res
as.data.frame(vif_res)
x<-as.data.frame(vif_res)
View(x)
names(x)
x.index
row.names(x)
vif_output <- lm(Attrition ~., data = dataNew)
vif_res <- as.data.frame(car::vif(vif_output))
summary(vif_res)
print(vif_res)
vif_names <- row.names(vif_res)
while(any(vif_res > 2)){
var_with_max_vif <- names(which(vif_res == max(vif_res)))
vif_names <- vif_names[!(vif_names) %in% var_with_max_vif]
def_form <- as.formula(paste("Attrition ~" ,paste(vif_names, collapse = " +"),sep = ""))
vif_output <- lm(def_form, data = attira)
vif_res <- car::vif(vif_output)
}
vif_names <- row.names(vif_res)
while(any(vif_res > 2)){
var_with_max_vif <- names(which(vif_res == max(vif_res)))
vif_names <- vif_names[!(vif_names) %in% var_with_max_vif]
def_form <- as.formula(paste("Attrition ~" ,paste(vif_names, collapse = " +"),sep = ""))
vif_output <- lm(def_form, data = dataNew)
vif_res <- car::vif(vif_output)
}
any(vif_res > 2)
any(vif_res > 10)
var_with_max_vif <- names(which(vif_res == max(vif_res)))
var_with_max_vif
row.names(which(vif_res == max(vif_res)))
which(vif_res == max(vif_res))
vif_res
col_index_to_remove <- c(2,4,6,7,11,12,13,16,19,24,25,26,27,35,36,37, 29, 40, 41,44) # VIF value < 2
dataNew <- dataNew[, -col_index_to_remove]
# First We split the data into modeldata and validationdata
set.seed(2017)
train <- sample(1:nrow(dataNew), nrow(dataNew)*.7)
test = -train
modeldata <- dataNew[train,]
validationdata <- dataNew[test,]
# Fitting the Logistic Regression Model
logmodel <- glm(Attrition ~., family=binomial(link="logit"), data = modeldata)
data <- read_csv("data/ibm-hr-analytics-employee-attrition-performance/WA_Fn-UseC_-HR-Employee-Attrition.csv")
data <- data[,-c(9,10,22,27)]
# Changig the class of variable from numeric to factor
cat_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance", "BusinessTravel")
remove_one_dummy <-  c("Education.1", "EnvironmentSatisfaction.1", "JobInvolvement.1", "JobLevel.1", "JobSatisfaction.1", "PerformanceRating.3", "RelationshipSatisfaction.1", "StockOptionLevel.0", "WorkLifeBalance.1", "BusinessTravel.Non.Travel")
getIndex <- function(name) {
grep(name, colnames(dataNew))
}
index <- unlist(lapply(remove_one_dummy, getIndex))
# Changig the class of variable from numeric to factor
cat_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance", "BusinessTravel")
remove_one_dummy <-  c("Education.1", "EnvironmentSatisfaction.1", "JobInvolvement.1", "JobLevel.1", "JobSatisfaction.1", "PerformanceRating.3", "RelationshipSatisfaction.1", "StockOptionLevel.0", "WorkLifeBalance.1", "BusinessTravel.Non.Travel")
getIndex <- function(name) {
grep(name, colnames(data))
}
index <- unlist(lapply(remove_one_dummy, getIndex))
data$Education <- factor(data$Education)
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobInvolvement <- factor(data$JobInvolvement)
data$JobLevel <- factor(data$JobLevel)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$PerformanceRating <- factor(data$PerformanceRating)
data$RelationshipSatisfaction <- factor(data$RelationshipSatisfaction)
data$StockOptionLevel <- factor(data$StockOptionLevel)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
data$BusinessTravel <- factor(data$BusinessTravel)
# Changig the class of variable from numeric to factor
cat_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance", "BusinessTravel")
index <- unlist(lapply(remove_one_dummy, getIndex))
data$Education <- factor(data$Education)
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobInvolvement <- factor(data$JobInvolvement)
data$JobLevel <- factor(data$JobLevel)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$PerformanceRating <- factor(data$PerformanceRating)
data$RelationshipSatisfaction <- factor(data$RelationshipSatisfaction)
data$StockOptionLevel <- factor(data$StockOptionLevel)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
data$BusinessTravel <- factor(data$BusinessTravel)
data$Attrition <- ifelse(data$Attrition == "Yes",1,0)
# Changig the class of variable from numeric to factor
cat_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance", "BusinessTravel")
data$Education <- factor(data$Education)
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobInvolvement <- factor(data$JobInvolvement)
data$JobLevel <- factor(data$JobLevel)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$PerformanceRating <- factor(data$PerformanceRating)
data$RelationshipSatisfaction <- factor(data$RelationshipSatisfaction)
data$StockOptionLevel <- factor(data$StockOptionLevel)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
data$BusinessTravel <- factor(data$BusinessTravel)
dataNew <- mlr::createDummyFeatures(data, cols = cat_vars)
remove_one_dummy <-  c("Education.1", "EnvironmentSatisfaction.1", "JobInvolvement.1", "JobLevel.1", "JobSatisfaction.1", "PerformanceRating.3", "RelationshipSatisfaction.1", "StockOptionLevel.0", "WorkLifeBalance.1", "BusinessTravel.Non.Travel")
getIndex <- function(name) {
grep(name, colnames(dataNew))
}
index <- unlist(lapply(remove_one_dummy, getIndex))
#Removing the dummy variable
dataNew <- dataNew[, -index]
#dataNew <- dataNew[,-c(3,7,11,16,25,26,32,37,39,50,51,58,61,65,69,75)]
# Removing the Multicollinearity variable - I have removed the code that does this. Don't worry about this. Used VIF function from car package to identify this. All the variables that had < 2 VIF value were removed.
#dataNew <- dataNew[,-c(4,6,7,10,13,25,26,35,36,42,43,47,48,52,55,59,60,61)]
str(dataNew)
vif_output <- lm(Attrition ~., data = dataNew)
vif_res <- as.data.frame(car::vif(vif_output))
summary(vif_res)
print(vif_res)
names(dataNew)
col_index_to_remove <- c(2,4,6,7,11,12,13,16,19,24,25,26,27,35,36,37, 29, 40, 41,44)+1 # VIF value < 2 (Accounting for the attrition variable coming in between Age and Dailyrate.)
dataNew <- dataNew[, -col_index_to_remove]
names(dataNew)
# First We split the data into modeldata and validationdata
set.seed(2017)
train <- sample(1:nrow(dataNew), nrow(dataNew)*.7)
test = -train
modeldata <- dataNew[train,]
validationdata <- dataNew[test,]
# Fitting the Logistic Regression Model
logmodel <- glm(Attrition ~., family=binomial(link="logit"), data = modeldata)
print(summary(logmodel))
# Accesing the predective ability of the logistic regression model
log_pred <- predict(logmodel,newdata=validationdata,type='response')
log_pred <- ifelse(log_pred>=0.5,1,0)
#table(log_pred,validationdata$Attrition)
caret::confusionMatrix(factor(log_pred),factor(validationdata$Attrition))
# Feature analysis
# Based upon the p-value of anova
anova(logmodel, test = "Chisq")
names(modeldata)
modelDa
modeldata$JobRole
unique(modeldata$JobRole)
# Fitting the Logistic Regression Model
logmodel2 <- glm(Attrition ~Age+Department+JobRole+MaritalStatus+YearsInCurrentRole+YearsWithCurrManager+JobInvolvement.4+JobLevel.2+StockOptionLevel.1+StockOptionLevel.2+WorkLifeBalance.3+WorkLifeBalance.4+BusinessTravel.Travel_Frequently, family=binomial(link="logit"), data = modeldata)
print(summary(logmodel2))
# Fitting the Logistic Regression Model
logmodel2 <- glm(Attrition ~Age+Department+YearsInCurrentRole+YearsWithCurrManager+JobInvolvement.4+JobLevel.2+StockOptionLevel.1+StockOptionLevel.2+WorkLifeBalance.3+WorkLifeBalance.4+BusinessTravel.Travel_Frequently, family=binomial(link="logit"), data = modeldata)
print(summary(logmodel2))
# Accesing the predictive ability of the logistic regression model
log_pred2 <- predict(logmodel2,newdata=validationdata2,type='response')
# Accesing the predictive ability of the logistic regression model
log_pred2 <- predict(logmodel2,newdata=validationdata,type='response')
log_pred2 <- ifelse(log_pred>=0.5,1,0)
table(log_pred2, validationdata$Attrition)
caret::confusionMatrix(factor(log_pred2),factor(validationdata2$Attrition))
# Accesing the predictive ability of the logistic regression model
log_pred2 <- predict(logmodel2,newdata=validationdata,type='response')
log_pred2 <- ifelse(log_pred>=0.5,1,0)
table(log_pred2, validationdata$Attrition)
caret::confusionMatrix(factor(log_pred2),factor(validationdata$Attrition))
# Fitting the Logistic Regression Model
logmodel2 <- glm(Attrition ~Age+Department+YearsInCurrentRole+YearsWithCurrManager+JobInvolvement.4+JobLevel.2+StockOptionLevel.1+StockOptionLevel.2+WorkLifeBalance.3+WorkLifeBalance.4+BusinessTravel.Travel_Frequently+JobRole+MaritalStatus, family=binomial(link="logit"), data = modeldata)
print(summary(logmodel2))
# Accesing the predictive ability of the logistic regression model
log_pred2 <- predict(logmodel2,newdata=validationdata,type='response')
log_pred2 <- ifelse(log_pred>=0.5,1,0)
table(log_pred2, validationdata$Attrition)
caret::confusionMatrix(factor(log_pred2),factor(validationdata$Attrition))
# Load required library
suppressMessages(library(ggplot2)) # Data Visualization
suppressMessages(library(readr)) # CSV file I/O, e.g. the read_csv function
suppressMessages(library(corrplot)) #visualization of correlation matrix
suppressMessages(library(gridExtra)) # Grid Graphics
suppressMessages(library(MASS)) # Modern Applied Statistics with S
suppressMessages(library(fastDummies)) # to create dummy variable
suppressMessages(library(ROCR)) # Thresold value
suppressMessages(library(caret))
suppressMessages(library(mlr))
data <- read_csv("data/ibm-hr-analytics-employee-attrition-performance/WA_Fn-UseC_-HR-Employee-Attrition.csv")
data <- data[,-c(9,10,22,27)]
# Changig the class of variable from numeric to factor
cat_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance", "BusinessTravel", "JobRole", "MaritalStatus")
data$Education <- factor(data$Education)
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobInvolvement <- factor(data$JobInvolvement)
data$JobLevel <- factor(data$JobLevel)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$PerformanceRating <- factor(data$PerformanceRating)
data$RelationshipSatisfaction <- factor(data$RelationshipSatisfaction)
data$StockOptionLevel <- factor(data$StockOptionLevel)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
data$BusinessTravel <- factor(data$BusinessTravel)
data$JobRole <- factor(data$JobRole)
data$MaritalStatus <- factor(data$MaritalStatus)
data$Attrition <- ifelse(data$Attrition == "Yes",1,0)
dataNew <- mlr::createDummyFeatures(data, cols = cat_vars)
names(dataNew)
dataNew <- mlr::createDummyFeatures(data, cols = cat_vars)
remove_one_dummy <-  c("Education.1", "EnvironmentSatisfaction.1", "JobInvolvement.1", "JobLevel.1", "JobSatisfaction.1", "PerformanceRating.3", "RelationshipSatisfaction.1", "StockOptionLevel.0", "WorkLifeBalance.1", "BusinessTravel.Non.Travel", "MaritalStatus.Divorced", "JobRole.Healthcare.Representative")
getIndex <- function(name) {
grep(name, colnames(dataNew))
}
index <- unlist(lapply(remove_one_dummy, getIndex))
#Removing the dummy variable
dataNew <- dataNew[, -index]
#dataNew <- dataNew[,-c(3,7,11,16,25,26,32,37,39,50,51,58,61,65,69,75)]
# Removing the Multicollinearity variable - I have removed the code that does this. Don't worry about this. Used VIF function from car package to identify this. All the variables that had < 2 VIF value were removed.
#dataNew <- dataNew[,-c(4,6,7,10,13,25,26,35,36,42,43,47,48,52,55,59,60,61)]
vif_output <- lm(Attrition ~., data = dataNew)
vif_res <- as.data.frame(car::vif(vif_output))
summary(vif_res)
print(vif_res)
vif_res %>% filter(GVIF > 2)
library(dplyr)
vif_res %>% filter(GVIF > 2)
vif_res %>% which(GVIF > 2)
?which
which(vif_res$GVIF > 2)
which(vif_res$GVIF < 2)
#col_index_to_remove <- c(2,4,6,7,9,10,11,14,16,19,24,25,26,27,35,36,37, 29, 40, 41,44)+1 # VIF value < 2
col_index_to_remove <- which(vif_res$GVIF < 2)+1 #(Accounting for the attrition variable coming in between Age and Dailyrate.)
dataNew <- dataNew[, -col_index_to_remove]
names(dataNew)
# First We split the data into modeldata and validationdata
set.seed(2017)
train <- sample(1:nrow(dataNew), nrow(dataNew)*.7)
test = -train
modeldata <- dataNew[train,]
validationdata <- dataNew[test,]
# First We split the data into modeldata and validationdata
set.seed(2017)
train <- sample(1:nrow(dataNew), nrow(dataNew)*.7)
test = -train
modeldata <- dataNew[train,]
validationdata <- dataNew[test,]
# First We split the data into modeldata and validationdata
set.seed(0)
train <- sample(1:nrow(dataNew), nrow(dataNew)*.7)
test = -train
modeldata <- dataNew[train,]
validationdata <- dataNew[test,]
# Fitting the Logistic Regression Model
logmodel <- glm(Attrition ~., family=binomial(link="logit"), data = modeldata)
print(summary(logmodel))
# Accesing the predective ability of the logistic regression model
log_pred <- predict(logmodel,newdata=validationdata,type='response')
log_pred <- ifelse(log_pred>=0.5,1,0)
#table(log_pred,validationdata$Attrition)
caret::confusionMatrix(factor(log_pred),factor(validationdata$Attrition))
# Plotting the ROC curve
res <- predict(logmodel, modeldata, type = "response")
ROCRPred <- prediction(res, modeldata$Attrition)
ROCRPerf <- performance(ROCRPred,"tpr","fpr")
# Plotting the ROC curve
res <- predict(logmodel, modeldata, type = "response")
ROCRPred <- ROCR::prediction(res, modeldata$Attrition)
ROCRPerf <- performance(ROCRPred,"tpr","fpr")
# Plotting the ROC curve
res <- predict(logmodel, modeldata, type = "response")
ROCRPred <- ROCR::prediction(res, modeldata$Attrition)
ROCRPerf <- ROCR::performance(ROCRPred,"tpr","fpr")
plot(ROCRPerf,colorize = TRUE, print.cutoffs.at = seq(0.1, by = 0.1))
# Feature analysis
# Based upon the p-value of anova
anova(logmodel, test = "Chisq")
avals <- anova(logmodel, test = "chisq")
avals <- anova(logmodel, test = "Chisq")
class(avals)
which(avals$`Pr(>Chi)` < 0.05)
which(avals$`Pr(>Chi)` > 0.05)
names(modeldata)
# Removing the variable whose p-value is greater than 0.05.
anova_cols_to_remove <- which(avals$`Pr(>Chi)` > 0.05)
modeldata2 <- modeldata[,-anova_cols_to_remove]
validationdata2 <- validationdata[,-anova_cols_to_remove]
# Fitting the Logistic Regression Model
logmodel2 <- glm(Attrition ~., family=binomial(link="logit"), data = modeldata2)
print(summary(logmodel2))
# Accesing the predictive ability of the logistic regression model
log_pred2 <- predict(logmodel2,newdata=validationdata,type='response')
log_pred2 <- ifelse(log_pred>=0.5,1,0)
table(log_pred2, validationdata$Attrition)
caret::confusionMatrix(factor(log_pred2),factor(validationdata$Attrition))
# Accesing the predictive ability of the logistic regression model
log_pred2 <- predict(logmodel2,newdata=validationdata2,type='response')
log_pred2 <- ifelse(log_pred>=0.5,1,0)
table(log_pred2, validationdata2$Attrition)
caret::confusionMatrix(factor(log_pred2),factor(validationdata2$Attrition))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(purrr)
library(e1071)
price <- c(18.09, 15.68, 23.10, 9.75, 2.29, 1.99, 15.60, .99, 10.99)
qty <- c( 10,7,14,4,1,1,8, 2, 6)
s_df <- tibble(price,qty)
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
ggplot(local_air) + geom_bar(aes(x = Month))
ggplot(local_air) + geom_bar(aes(x = Day))
ggplot(local_air, aes(x=Solar.R, y=Ozone)) + geom_point()
ggplot(local_air, aes(x=Wind, y=Ozone)) + geom_point()
ggplot(local_air, aes(x=Temp, y=Ozone)) + geom_point()
library(corrplot)
price <- c(18.09, 15.68, 23.10, 9.75, 2.29, 1.99, 15.60, .99, 10.99)
qty <- c( 10,7,14,4,1,1,8, 2, 6)
s_df <- tibble(price,qty)
pred <- lm(formula = price ~ qty, data = s_df)
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
sapply(airquality, function(x) sum(is.na(x)))
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
sapply(airquality, function(x) sum(is.na(x)))
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
#sapply(airquality, function(x) sum(is.na(x)))
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
sapply(airquality, function(x) sum(is.na(x)))
View(local_air)
pred_oz <- lm(formula = Ozone ~ Solar.R + Wind + Temp, data = local_air)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(purrr)
library(e1071)
price <- c(18.09, 15.68, 23.10, 9.75, 2.29, 1.99, 15.60, .99, 10.99)
qty <- c( 10,7,14,4,1,1,8, 2, 6)
s_df <- tibble(price,qty)
pred_pr <- lm(formula = price ~ qty, data = s_df)
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
sapply(airquality, function(x) sum(is.na(x)))
ggplot(local_air) + geom_bar(aes(x = Month))
ggplot(local_air) + geom_bar(aes(x = Day))
# The visualizations for Month and Day show that the distributions between Month, Day and Count are relatively and respectively uniform.
ggplot(local_air, aes(x=Solar.R, y=Ozone)) + geom_point() # Solar and Ozone levels are positively and weakly correlated
ggplot(local_air, aes(x=Wind, y=Ozone)) + geom_point() #Wind and Ozone levels are negatively correlated
ggplot(local_air, aes(x=Temp, y=Ozone)) + geom_point() #Temp and Ozone levels are positively correlated
library(corrplot)
pred_oz <- lm(formula = Ozone ~ Solar.R + Wind + Temp, data = local_air)
View(airquality)
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
sapply(airquality, function(x) sum(is.na(x))) # Identify missing values
sapply(airquality, function(x) sd(x)) # Identify instances of std dev = 0
library(purrr)
require("datasets")
data("airquality")
local_air <- airquality
sapply(airquality, function(x) sum(is.na(x))) # Identify missing values
sapply(airquality, function(x) sd(x)) # Identify instances of std dev = 0
dist_oz <- rnorm(local_air$Ozone)
dist_oz <- dnorm(local_air$Ozone, mean(local_air$Ozone), sd(local_air$Ozone))
dist_oz <- dnorm(local_air$Ozone, mean(local_air$Ozone), sd(local_air$Ozone))
dist_oz <- dnorm(local_air$Ozone, mean(local_air$Ozone), sd(local_air$Ozone))
dist_oz <- dnorm(local_air$Ozone, mean(local_air$Ozone), sd(local_air$Ozone))
dist_oz <- dnorm(local_air$Ozone, mean(local_air$Ozone), sd(local_air$Ozone))
dist_oz <- dnorm(local_air$Ozone)
dist_oz <- dnorm(local_air$Ozone)
dist_oz <- rnorm(local_air$Ozone, mean(local_air$Ozone), sd(local_air$Ozone))
dist_oz <- rnorm(local_air$Ozone)
dist_oz <- rnorm(local_air$Ozone)
dist_oz <- rnorm(local_air$Ozone)
dist_wd <- rnorm(local_air$Wind)
dist_tp <- rnorm(local_air$Temp)
dist_oz <- rnorm(local_air$Ozone)
dist_wd <- rnorm(local_air$Wind)
dist_tp <- rnorm(local_air$Temp)
plot(function(x) dist_oz, -50, 50,
main = "log { Normal density }")
dist_oz <- dnorm(local_air$Ozone)
dist_wd <- rnorm(local_air$Wind)
dist_tp <- rnorm(local_air$Temp)
plot(function(x) dist_oz, -50, 50,
main = "log { Normal density }")
View(pred)
View(local_air)
pred_gv <- pred$coefficients[[1]]*(8.3) + pred$coefficients[[2]]*(77) + pred$coefficients[[3]]*(200)s
pred_gv <- pred$coefficients[[1]]*(8.3) + pred$coefficients[[2]]*(77) + pred$coefficients[[3]]*(200)
library(corrplot)
cor(local_air$Ozone,local_air$Solar.R)
cor(local_air$Ozone,local_air$Wind)
cor(local_air$Ozone,local_air$Temp)
library(corrplot)
cor(local_air$Solar.R,local_air$Ozone)
cor(local_air$Ozone,local_air$Wind)
cor(local_air$Ozone,local_air$Temp)
library(corrplot)
cor(local_air$Solar.R,local_air$Ozone)
cor(local_air$Wind,local_air$Ozone)
cor(local_air$Temp,local_air$Ozone)
# It appears that temperature and Ozone levels have the highest correlation
library(corrplot)
cor(local_air$Solar.R,local_air$Ozone)
cor(local_air$Wind,local_air$Ozone)
cor(local_air$Temp,local_air$Ozone)
# It appears that temperature and Ozone levels have the highest correlation
library(corrplot)
cor(local_air$Solar.R,local_air$Ozone)
cor(local_air$Wind,local_air$Ozone)
cor(local_air$Temp,local_air$Ozone)
# It appears that temperature and Ozone levels have the highest correlation
library(corrplot)
cor(airquality$Solar.R,airquality$Ozone)
cor(local_air$Wind,local_air$Ozone)
cor(local_air$Temp,local_air$Ozone)
# It appears that temperature and Ozone levels have the highest correlation
library(corrplot)
cor(airquality$Solar.R,airquality$Ozone)
cor(local_air$Wind,local_air$Ozone)
cor(local_air$Temp,local_air$Ozone)
# It appears that temperature and Ozone levels have the highest correlation
ls
ls()
dir()
getwd()
setwd("/home/mancunian92/Documents/courses/causal_inference/prof_repo/HW/hw2_answers/")
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
library("bnlearn")
install.packages("bnlearn")
library(bnlearn)
install.packages(bnlearn)
install.packages("bnlearn")
library("bnlearn")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Rgraphviz")
library("RgraphViz")
library(Rgraphviz)
